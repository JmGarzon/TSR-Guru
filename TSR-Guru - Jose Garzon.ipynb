{"cells":[{"cell_type":"markdown","metadata":{},"source":["# TSR Guru\n","\n","### Made by: Jose Miguel Garzón Vargas\n","Universidad EAFIT\n","\n","TSR Guru employs the Retrieval-Augmented Generation (RAG) approach to facilitate the understanding of scientific articles within the Table Structure Recognition (TSR) domain. Utilizing embeddings stored in Chroma DB, the system retrieves and augments queries. Initially, queries are transformed into embeddings and matched against similar documents stored in Chroma DB. These retrieved documents then serve as context for queries directed to the AzureChatOpenAI API. This integration ensures that responses provided through AzureChatOpenAI API are not only accurate but also enriched with insights from relevant literature, simplifying access to and comprehension of TSR content."]},{"cell_type":"markdown","metadata":{},"source":["### Load secrets"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"VZI4XoEZuC8B"},"outputs":[],"source":["from dotenv import load_dotenv\n","import os\n","\n","load_dotenv()\n","\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n","OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n","OPENAI_API_TYPE = os.getenv('OPENAI_API_TYPE')"]},{"cell_type":"markdown","metadata":{"id":"Ot1CoDdKuC8D"},"source":["### Load files"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zwux38XUuC8L"},"outputs":[{"name":"stdout","output_type":"stream","text":["All documents loaded!\n"]}],"source":["from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","FOLDER_PATH = r\".\\TSR-docs\"\n","\n","# Create the text splitter\n","splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","documents = []\n","# Create a loader for the `rtdocs/python.langchain.com/en/latest` folder\n","for file_name in os.listdir(FOLDER_PATH):\n","    # Join the folder path with the file name to get the full path\n","    file_path = os.path.join(FOLDER_PATH, file_name)\n","    # Check if the current path is a file (not a folder)\n","    if os.path.isfile(file_path):\n","        loader = PyPDFLoader(file_path)\n","        raw_documents = loader.load()\n","\n","\n","        # Split the documents\n","        documents.extend(splitter.split_documents(raw_documents))\n","print(f\"All documents loaded!\")\n"]},{"cell_type":"markdown","metadata":{"id":"NDt-AmtTuC8O"},"source":["### Embedding the documents"]},{"cell_type":"markdown","metadata":{},"source":["#### Cost estimation"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5MArDTyquC8O"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total tokens: 384359 - cost: $0.15\n"]}],"source":["# Import tiktoken\n","import tiktoken\n","\n","# Create an encoder\n","encoder = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n","\n","# Count tokens in each document\n","doc_tokens = [len(encoder.encode(doc.page_content)) for doc in documents]\n","\n","# Calculate the sum of all token counts\n","total_tokens = sum(doc_tokens)\n","\n","# Calculate a cost estimate\n","cost = (total_tokens/1000) * 0.0004\n","print(f\"Total tokens: {total_tokens} - cost: ${cost:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"a3pT2p7QuC8P"},"source":["### Embeddings generation\n","\n","Using ChromaDB to store the embeddings. We’ll skip this if we’ve already saved the embedding"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jjny3yPJuC8P"},"outputs":[],"source":["from langchain.vectorstores import Chroma\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Create the mebedding function\n","embedding_function = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\",chunk_size = 1)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2aBhDj2MuC8Q"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\jmgarzonv\\Desktop\\EAFIT\\Experiencias - RAG\\Building AI APP\\.venv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n","  warnings.warn(\n"]}],"source":["# Create a database from the documents and embedding function\n","db = Chroma.from_documents(documents=documents[:1], embedding=embedding_function, persist_directory=\"TSR-embeddings\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"LmBkTf4WuC8Q"},"outputs":[],"source":["# Persist the data to disk\n","# db.persist() We already have the data"]},{"cell_type":"markdown","metadata":{},"source":["### Embeddings loading\n","Since the embeddings are already created, we'll just load them from the files:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3K4FUGKVuC8R"},"outputs":[],"source":["# Import chroma\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Create the embedding function\n","embedding = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\",chunk_size = 1)\n","db = Chroma(persist_directory=\"TSR-embeddings\", embedding_function=embedding)"]},{"cell_type":"markdown","metadata":{"id":"FWyFg7bDuC8S"},"source":["### Create a QA chain using RAG"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["question = \"What is TSR?\"\n","question = \"Main challenges of TSR\"\n","question = \"What are some approaches to solve the TSR problem?\"\n","question = \"Which datasets are useful and why?\"\n","question = \"Where should I start if I want to compare TSR models?\"\n","question = \"How can I evaluate a TSR model performance?\"\n","question = \"Explain the details of the GriTS  metric\"\n","question = \"Explain the details of the TEDS  metric\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TF9wSc5EuC8S"},"outputs":[],"source":["# Import\n","from langchain.prompts import PromptTemplate\n","from langchain.chains.llm import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.schema import HumanMessage\n","\n","# Query the database as store the results as `context_docs`\n","context_docs = db.similarity_search(question)\n","\n","# Create a prompt with 2 variables: `context` and `question`\n","prompt = PromptTemplate(\n","    template=\"\"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","\n","<context>\n","{context}\n","</context>\n","\n","Question: {question}\n","Helpful Answer, formatted in markdown:\"\"\",\n","    input_variables=[\"context\", \"question\"]\n",")\n","\n","# Create an LLM with ChatOpenAI\n","llm = AzureChatOpenAI(\n","    openai_api_base=OPENAI_API_BASE,\n","    openai_api_version=OPENAI_API_VERSION,\n","    deployment_name=\"gpt-35-turbo\",\n","    openai_api_key=OPENAI_API_KEY,\n","    openai_api_type=OPENAI_API_TYPE,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"KiZzEvuKuC8S"},"outputs":[{"name":"stdout","output_type":"stream","text":["User:\n","\t-Explain the details of the TEDS  metric\n","\n","TSR Guru:\n","The TEDS (Tree-Edit-Distance-Based Similarity) metric is a similarity measure used to evaluate the quality of table recognition methods. It was introduced in a research paper [37] and is calculated based on the tree structure of HTML tags representing the prediction and ground-truth tables.\n","\n","The TEDS metric is calculated using the following formula:\n","\n","TEDS(Ta, Tb) = 1 - EditDist(Ta, Tb) / max(|Ta|, |Tb|)\n","\n","Where Ta and Tb represent tables in tree structure HTML format, and EditDist represents the tree-edit distance between the two tables. |T| represents the number of nodes in the table.\n","\n","The TEDS metric is used to measure the similarity between predicted and ground-truth tables. A higher TEDS value indicates a higher similarity between the two tables. It is a commonly used evaluation metric in the field of table recognition.\n"]}],"source":["# Create the chain\n","qa_chain = LLMChain(llm=llm, prompt=prompt)\n","\n","# Call the chain\n","result = qa_chain({\n","    \"question\": question,\n","    \"context\": \"\\n\".join([doc.page_content for doc in context_docs])\n","})\n","\n","# Print the result\n","print(f\"User:\\n\\t-{question}\\n\")\n","print(f\"TSR Guru:\\n{result['text']}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"env-rag","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
