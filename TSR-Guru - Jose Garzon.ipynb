{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VZI4XoEZuC8B"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain==0.0.316\n","  Downloading langchain-0.0.316-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (2.0.28)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (3.9.3)\n","Collecting anyio<4.0 (from langchain==0.0.316)\n","  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (0.5.14)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.316)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Collecting langsmith<0.1.0,>=0.0.43 (from langchain==0.0.316)\n","  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: numpy<2,>=1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (1.10.14)\n","Requirement already satisfied: requests<3,>=2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from langchain==0.0.316) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.9.4)\n","Requirement already satisfied: idna>=2.8 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from anyio<4.0->langchain==0.0.316) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from anyio<4.0->langchain==0.0.316) (1.3.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (0.9.0)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.316)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.316) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests<3,>=2->langchain==0.0.316) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests<3,>=2->langchain==0.0.316) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests<3,>=2->langchain==0.0.316) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.316) (3.0.3)\n","Requirement already satisfied: packaging>=17.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (1.0.0)\n","Downloading langchain-0.0.316-py3-none-any.whl (1.9 MB)\n","   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n","   - -------------------------------------- 0.1/1.9 MB 1.1 MB/s eta 0:00:02\n","   ------ --------------------------------- 0.3/1.9 MB 2.9 MB/s eta 0:00:01\n","   ---------------- ----------------------- 0.8/1.9 MB 5.4 MB/s eta 0:00:01\n","   ---------------------------------------- 1.9/1.9 MB 10.1 MB/s eta 0:00:00\n","Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n","   ---------------------------------------- 0.0/80.9 kB ? eta -:--:--\n","   ---------------------------------------- 80.9/80.9 kB ? eta 0:00:00\n","Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n","   ---------------------------------------- 0.0/56.5 kB ? eta -:--:--\n","   ---------------------------------------- 56.5/56.5 kB ? eta 0:00:00\n","Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Installing collected packages: jsonpointer, anyio, langsmith, jsonpatch, langchain\n","  Attempting uninstall: anyio\n","    Found existing installation: anyio 4.3.0\n","    Uninstalling anyio-4.3.0:\n","      Successfully uninstalled anyio-4.3.0\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.0.191\n","    Uninstalling langchain-0.0.191:\n","      Successfully uninstalled langchain-0.0.191\n","Successfully installed anyio-3.7.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.316 langsmith-0.0.92\n","Requirement already satisfied: chromadb==0.3.29 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (0.3.29)\n","Requirement already satisfied: pandas>=1.3 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (2.2.1)\n","Requirement already satisfied: requests>=2.28 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (2.31.0)\n","Requirement already satisfied: pydantic<2.0,>=1.9 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (1.10.14)\n","Requirement already satisfied: hnswlib>=0.7 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (0.8.0)\n","Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (0.7.1)\n","Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (0.10.0)\n","Requirement already satisfied: fastapi==0.85.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (0.85.1)\n","Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.27.1)\n","Requirement already satisfied: numpy>=1.21.6 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (1.26.4)\n","Requirement already satisfied: posthog>=2.4.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (3.5.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (4.10.0)\n","Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (3.4.0)\n","Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (1.17.1)\n","Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (0.15.2)\n","Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (4.66.2)\n","Requirement already satisfied: overrides>=7.3.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from chromadb==0.3.29) (7.7.0)\n","Requirement already satisfied: starlette==0.20.4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from fastapi==0.85.1->chromadb==0.3.29) (0.20.4)\n","Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (3.7.1)\n","Requirement already satisfied: certifi in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.2.2)\n","Requirement already satisfied: urllib3>=1.26 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2.2.1)\n","Requirement already satisfied: pytz in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.1)\n","Requirement already satisfied: zstandard in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (0.22.0)\n","Requirement already satisfied: lz4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (4.3.3)\n","Requirement already satisfied: coloredlogs in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (15.0.1)\n","Requirement already satisfied: flatbuffers in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (23.5.26)\n","Requirement already satisfied: packaging in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (23.2)\n","Requirement already satisfied: protobuf in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (4.25.3)\n","Requirement already satisfied: sympy in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (1.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.29) (2.9.0.post0)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.29) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.16.0)\n","Requirement already satisfied: monotonic>=1.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.29) (2.2.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.28->chromadb==0.3.29) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.28->chromadb==0.3.29) (3.6)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb==0.3.29) (0.21.4)\n","Requirement already satisfied: colorama in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from tqdm>=4.65.0->chromadb==0.3.29) (0.4.6)\n","Requirement already satisfied: click>=7.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.29) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (1.0.1)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (6.0.1)\n","Requirement already satisfied: watchfiles>=0.13 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (12.0)\n","Requirement already satisfied: filelock in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.3.29) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.3.29) (2024.2.0)\n","Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.29) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.29) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (1.3.1)\n","Requirement already satisfied: pyreadline3 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.29) (3.4.1)\n","Requirement already satisfied: tiktoken in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (0.6.0)\n","Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Requirement already satisfied: beautifulsoup4 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from beautifulsoup4) (2.5)\n"]}],"source":["# install langchain (version 0.0.191)\n","!pip install langchain==0.0.316\n","# install chromadb\n","!pip install chromadb==0.3.29\n","# install tiktoken\n","!pip install tiktoken\n","# install beautifulsoup4\n","!pip install beautifulsoup4"]},{"cell_type":"markdown","metadata":{"id":"Ot1CoDdKuC8D"},"source":["# Task 1: Load Data\n","\n","To be able to embed and store data, we need to provide LangChain with Documents. This is easy to achieve in LangChain thanks to Document Loaders. In our case, we're targeting a \"Read the docs\" documentation, for which there is a loader ReadTheDocsLoader. In the folder rtdocs, you'll find all the HTML files from the [LangChain documentation](https://python.langchain.com/en/latest/index.html).\n","\n","```bash\n","wget -r -A.html -P rtdocs https://python.langchain.com/en/latest/\n","```\n","\n","In a bash console execute this code:\n","```bash\n","unzip contents.zip\n","```\n","\n","Our first task is to load these HTML files as documents that we can use with langchain: we're going to use the ReadTheDocsLoader. It will read the directory containing all HTML files and transform them into Document objects.\n","\n","`ReadTheDocsLoader` will read each HTML file, remove HTML tags to only keep the text and return it as a Document. At the end of this task, we'll have a variable raw_documents containing a list of Document: one Document per HTML file."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zwux38XUuC8L"},"outputs":[],"source":["# Import ReadTheDocsLoader\n","from langchain.document_loaders import ReadTheDocsLoader\n","\n","# Create a loader for the `rtdocs/python.langchain.com/en/latest` folder\n","loader = ReadTheDocsLoader(\"rtdocs/python.langchain.com/en/latest\", features=\"html.parser\", encoding='utf-8')\n","\n","# Load the data\n","raw_documents = loader.load()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jluZ26M1uC8M"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size raw documents:  999\n"]}],"source":["print(\"Size raw documents: \",len(raw_documents))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["page_content='.rst\\n.pdf\\nDeploying LLMs in Production\\n Contents \\nOutline\\nDesigning a Robust LLM Application Service\\nMonitoring\\nFault tolerance\\nZero down time upgrade\\nLoad balancing\\nMaintaining Cost-Efficiency and Scalability\\nSelf-hosting models\\nResource Management and Auto-Scaling\\nUtilizing Spot Instances\\nIndependent Scaling\\nBatching requests\\nEnsuring Rapid Iteration\\nModel composition\\nCloud providers\\nInfrastructure as Code (IaC)\\nCI/CD\\nDeploying LLMs in Production#\\nIn todayâ€™s fast-paced technological landscape, the use of Large Language Models (LLMs) is rapidly expanding. As a result, itâ€™s crucial for developers to understand how to effectively deploy these models in production environments. LLM interfaces typically fall into two categories:\\nCase 1: Utilizing External LLM Providers (OpenAI, Anthropic, etc.)In this scenario, most of the computational burden is handled by the LLM providers, while LangChain simplifies the implementation of business logic around these services. This approach includes features such as prompt templating, chat message generation, caching, vector embedding database creation, preprocessing, etc.\\nCase 2: Self-hosted Open-Source ModelsAlternatively, developers can opt to use smaller, yet comparably capable, self-hosted open-source LLM models. This approach can significantly decrease costs, latency, and privacy concerns associated with transferring data to external LLM providers.\\nRegardless of the framework that forms the backbone of your product, deploying LLM applications comes with its own set of challenges. Itâ€™s vital to understand the trade-offs and key considerations when evaluating serving frameworks.\\nOutline#\\nThis guide aims to provide a comprehensive overview of the requirements for deploying LLMs in a production setting, focusing on:\\nDesigning a Robust LLM Application Service\\nMaintaining Cost-Efficiency\\nEnsuring Rapid Iteration\\nUnderstanding these components is crucial when assessing serving systems. LangChain integrates with several open-source projects designed to tackle these issues, providing a robust framework for productionizing your LLM applications. Some notable frameworks include:\\nRay Serve\\nBentoML\\nModal\\nThese links will provide further information on each ecosystem, assisting you in finding the best fit for your LLM deployment needs.\\nDesigning a Robust LLM Application Service#\\nWhen deploying an LLM service in production, itâ€™s imperative to provide a seamless user experience free from outages. Achieving 24/7 service availability involves creating and maintaining several sub-systems surrounding your application.\\nMonitoring#\\nMonitoring forms an integral part of any system running in a production environment. In the context of LLMs, it is essential to monitor both performance and quality metrics.\\nPerformance Metrics: These metrics provide insights into the efficiency and capacity of your model. Here are some key examples:\\nQuery per second (QPS): This measures the number of queries your model processes in a second, offering insights into its utilization.\\nLatency: This metric quantifies the delay from when your client sends a request to when they receive a response.\\nTokens Per Second (TPS): This represents the number of tokens your model can generate in a second.\\nQuality Metrics: These metrics are typically customized according to the business use-case. For instance, how does the output of your system compare to a baseline, such as a previous version? Although these metrics can be calculated offline, you need to log the necessary data to use them later.\\nFault tolerance#\\nYour application may encounter errors such as exceptions in your model inference or business logic code, causing failures and disrupting traffic. Other potential issues could arise from the machine running your application, such as unexpected hardware breakdowns or loss of spot-instances during high-demand periods. One way to mitigate these risks is by increasing redundancy through replica scaling and implementing recovery mechanisms for failed replicas. However, model replicas arenâ€™t the only potential points of failure. Itâ€™s essential to build resilience against various failures that could occur at any point in your stack.\\nZero down time upgrade#\\nSystem upgrades are often necessary but can result in service disruptions if not handled correctly. One way to prevent downtime during upgrades is by implementing a smooth transition process from the old version to the new one. Ideally, the new version of your LLM service is deployed, and traffic gradually shifts from the old to the new version, maintaining a constant QPS throughout the process.\\nLoad balancing#\\nLoad balancing, in simple terms, is a technique to distribute work evenly across multiple computers, servers, or other resources to optimize the utilization of the system, maximize throughput, minimize response time, and avoid overload of any single resource. Think of it as a traffic officer directing cars (requests) to different roads (servers) so that no single road becomes too congested.\\nThere are several strategies for load balancing. For example, one common method is the Round Robin strategy, where each request is sent to the next server in line, cycling back to the first when all servers have received a request. This works well when all servers are equally capable. However, if some servers are more powerful than others, you might use a Weighted Round Robin or Least Connections strategy, where more requests are sent to the more powerful servers, or to those currently handling the fewest active requests. Letâ€™s imagine youâ€™re running a LLM chain. If your application becomes popular, you could have hundreds or even thousands of users asking questions at the same time. If one server gets too busy (high load), the load balancer would direct new requests to another server that is less busy. This way, all your users get a timely response and the system remains stable.\\nMaintaining Cost-Efficiency and Scalability#\\nDeploying LLM services can be costly, especially when youâ€™re handling a large volume of user interactions. Charges by LLM providers are usually based on tokens used, making a chat system inference on these models potentially expensive. However, several strategies can help manage these costs without compromising the quality of the service.\\nSelf-hosting models#\\nSeveral smaller and open-source LLMs are emerging to tackle the issue of reliance on LLM providers. Self-hosting allows you to maintain similar quality to LLM provider models while managing costs. The challenge lies in building a reliable, high-performing LLM serving system on your own machines.\\nResource Management and Auto-Scaling#\\nComputational logic within your application requires precise resource allocation. For instance, if part of your traffic is served by an OpenAI endpoint and another part by a self-hosted model, itâ€™s crucial to allocate suitable resources for each. Auto-scalingâ€”adjusting resource allocation based on trafficâ€”can significantly impact the cost of running your application. This strategy requires a balance between cost and responsiveness, ensuring neither resource over-provisioning nor compromised application responsiveness.\\nUtilizing Spot Instances#\\nOn platforms like AWS, spot instances offer substantial cost savings, typically priced at about a third of on-demand instances. The trade-off is a higher crash rate, necessitating a robust fault-tolerance mechanism for effective use.\\nIndependent Scaling#\\nWhen self-hosting your models, you should consider independent scaling. For example, if you have two translation models, one fine-tuned for French and another for Spanish, incoming requests might necessitate different scaling requirements for each.\\nBatching requests#\\nIn the context of Large Language Models, batching requests can enhance efficiency by better utilizing your GPU resources. GPUs are inherently parallel processors, designed to handle multiple tasks simultaneously. If you send individual requests to the model, the GPU might not be fully utilized as itâ€™s only working on a single task at a time. On the other hand, by batching requests together, youâ€™re allowing the GPU to work on multiple tasks at once, maximizing its utilization and improving inference speed. This not only leads to cost savings but can also improve the overall latency of your LLM service.\\nIn summary, managing costs while scaling your LLM services requires a strategic approach. Utilizing self-hosting models, managing resources effectively, employing auto-scaling, using spot instances, independently scaling models, and batching requests are key strategies to consider. Open-source libraries such as Ray Serve and BentoML are designed to deal with these complexities.\\nEnsuring Rapid Iteration#\\nThe LLM landscape is evolving at an unprecedented pace, with new libraries and model architectures being introduced constantly. Consequently, itâ€™s crucial to avoid tying yourself to a solution specific to one particular framework. This is especially relevant in serving, where changes to your infrastructure can be time-consuming, expensive, and risky. Strive for infrastructure that is not locked into any specific machine learning library or framework, but instead offers a general-purpose, scalable serving layer. Here are some aspects where flexibility plays a key role:\\nModel composition#\\nDeploying systems like LangChain demands the ability to piece together different models and connect them via logic. Take the example of building a natural language input SQL query engine. Querying an LLM and obtaining the SQL command is only part of the system. You need to extract metadata from the connected database, construct a prompt for the LLM, run the SQL query on an engine, collect and feed back the response to the LLM as the query runs, and present the results to the user. This demonstrates the need to seamlessly integrate various complex components built in Python into a dynamic chain of logical blocks that can be served together.\\nCloud providers#\\nMany hosted solutions are restricted to a single cloud provider, which can limit your options in todayâ€™s multi-cloud world. Depending on where your other infrastructure components are built, you might prefer to stick with your chosen cloud provider.\\nInfrastructure as Code (IaC)#\\nRapid iteration also involves the ability to recreate your infrastructure quickly and reliably. This is where Infrastructure as Code (IaC) tools like Terraform, CloudFormation, or Kubernetes YAML files come into play. They allow you to define your infrastructure in code files, which can be version controlled and quickly deployed, enabling faster and more reliable iterations.\\nCI/CD#\\nIn a fast-paced environment, implementing CI/CD pipelines can significantly speed up the iteration process. They help automate the testing and deployment of your LLM applications, reducing the risk of errors and enabling faster feedback and iteration.\\nprevious\\nDeployments\\nnext\\nTracing\\n Contents\\n  \\nOutline\\nDesigning a Robust LLM Application Service\\nMonitoring\\nFault tolerance\\nZero down time upgrade\\nLoad balancing\\nMaintaining Cost-Efficiency and Scalability\\nSelf-hosting models\\nResource Management and Auto-Scaling\\nUtilizing Spot Instances\\nIndependent Scaling\\nBatching requests\\nEnsuring Rapid Iteration\\nModel composition\\nCloud providers\\nInfrastructure as Code (IaC)\\nCI/CD\\nBy Harrison Chase\\n    \\n      Â© Copyright 2023, Harrison Chase.\\n      \\n  Last updated on Jun 06, 2023.\\n  ' metadata={'source': 'rtdocs\\\\python.langchain.com\\\\en\\\\latest\\\\additional_resources\\\\deploy_llms.html'}\n"]}],"source":["print(raw_documents[0])"]},{"cell_type":"markdown","metadata":{"id":"Kw6VSvvwuC8M"},"source":["# Task 2: Slice the documents into smaller chunks\n","\n","Now, we turned each HTML file into a Document. These files may be very long, and are potentially too large to embed fully. It's also a good practice to avoid embedding large documents:\n","- long documents often contain several concepts. Retrieval will be easier if each concept is indexed separately;\n","- retrieved documents will be injected in a prompt, so keeping them short will keep the prompt small.\n","\n","LangChain has a collection of tools to do this:\n","[Text Splitters](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html).\n","\n","We'll be using the most straightfoward one and simplest to use:\n","the [Recursive Character Text Splitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html).\n","\n","*The `recursive text splitter` will recursively reduce the input by splitting it by paragraph, then sentences, then words as needed until the chunk is small enough.*\n","â€‹"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"v_EaCZmPuC8N"},"outputs":[],"source":["# Import RecursiveCharacterTextSplitter\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Create the text splitter\n","splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","\n","# Split the documents\n","documents = splitter.split_documents(raw_documents)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"omb6HqtjuC8N"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size documents:  7538\n"]}],"source":["print(\"Size documents: \",len(documents))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DN0Vw8a0uC8N"},"outputs":[{"data":{"text/plain":["Document(page_content='.rst\\n.pdf\\nDeploying LLMs in Production\\n Contents \\nOutline\\nDesigning a Robust LLM Application Service\\nMonitoring\\nFault tolerance\\nZero down time upgrade\\nLoad balancing\\nMaintaining Cost-Efficiency and Scalability\\nSelf-hosting models\\nResource Management and Auto-Scaling\\nUtilizing Spot Instances\\nIndependent Scaling\\nBatching requests\\nEnsuring Rapid Iteration\\nModel composition\\nCloud providers\\nInfrastructure as Code (IaC)\\nCI/CD\\nDeploying LLMs in Production#\\nIn todayâ€™s fast-paced technological landscape, the use of Large Language Models (LLMs) is rapidly expanding. As a result, itâ€™s crucial for developers to understand how to effectively deploy these models in production environments. LLM interfaces typically fall into two categories:', metadata={'source': 'rtdocs\\\\python.langchain.com\\\\en\\\\latest\\\\additional_resources\\\\deploy_llms.html'})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["documents[0]"]},{"cell_type":"markdown","metadata":{"id":"NDt-AmtTuC8O"},"source":["# Task 3: count tokens and get a cost estimate of embedding\n","\n","We're ready to embed our documents. Before we do so, we'd like to get an idea of how big it is and how much it will cost to embed. To do so, we'll use the [`tiktoken`](https://github.com/openai/tiktoken) library. tiktoken allows to encode and decode strings of text into tokens. In our case, we're mostly interested in how many tokens our documents translate to.\n","\n","> ðŸ’¡ To better understand what a token is to GPT, head to [OpenAI's Tokenizer page](https://platform.openai.com/tokenizer) where you can see how a text translates to tokens.\n","\n","Prices for different models in OpenAI can be found on their [pricing page](https://openai.com/pricing).\n","\n","Prices for different models in Azure OpenAI can be found on their [pricing page]([Title](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5MArDTyquC8O"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total tokens: 1530817 - cost: $0.61\n"]}],"source":["# Import tiktoken\n","import tiktoken\n","\n","# Create an encoder\n","encoder = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n","\n","# Count tokens in each document\n","doc_tokens = [len(encoder.encode(doc.page_content)) for doc in documents]\n","\n","# Calculate the sum of all token counts\n","total_tokens = sum(doc_tokens)\n","\n","# Calculate a cost estimate\n","cost = (total_tokens/1000) * 0.0004\n","print(f\"Total tokens: {total_tokens} - cost: ${cost:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"a3pT2p7QuC8P"},"source":["# Task 4: embed the documents and store embeddings in the vector database\n","\n","We'll want to save the embeddings into a database. LangChain can take care of all that using a [Vector Store](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html).\n","\n","There are plenty of vector stores to choose from (see the [full list](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html)). Today we'll use [Chroma](https://docs.trychroma.com/), but you could be using any other as they have the same interface in LangChain. Once again you'll need to try many of them to see which best fits your use case: some vector stores have specific features (like multimodality or multilingual), so be sure to check them out.\n","\n","Chroma is simple to use and can be persisted to disk. If you do not whish to embed the full set of documents yourself, feel free to skip this step and use the provided folder `chroma-data-langchain-docs`: we've already embedded all documents and persisted it in this folder."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TkyLvGL2uC8P"},"outputs":[],"source":["# set the environment variables needed for openai package to know to reach out to azure\n","import os\n","\n","OPENAI_API_KEY=\"1c8ea8ebab1f40ab888906d7abcc8b4c\"\n","OPENAI_API_BASE=\"https://clasebi.openai.azure.com/\"\n","OPENAI_API_VERSION=\"2023-03-15-preview\"\n","OPENAI_API_TYPE=\"azure\"\n","\n","os.environ[\"OPENAI_API_TYPE\"] = OPENAI_API_TYPE\n","os.environ[\"OPENAI_API_BASE\"] = OPENAI_API_BASE\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n","os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"nqo678q8uC8P"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai==0.28.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (0.28.1)\n","Requirement already satisfied: requests>=2.20 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from openai==0.28.1) (2.31.0)\n","Requirement already satisfied: tqdm in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from openai==0.28.1) (4.66.2)\n","Requirement already satisfied: aiohttp in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from openai==0.28.1) (3.9.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.9.4)\n","Requirement already satisfied: colorama in c:\\users\\jmgarzonv\\desktop\\eafit\\experiencias - rag\\building ai app\\.venv\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n"]}],"source":["!pip install openai==0.28.1"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"jjny3yPJuC8P"},"outputs":[],"source":["# Import chroma\n","from langchain.vectorstores import Chroma\n","\n","# Import OpenAIEmbeddings\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Create the mebedding function\n","embedding_function = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\",chunk_size = 1)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"zcbWKiQXuC8P"},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.012424956126922663, 0.010575136213262644, 0.0013741046479578078, -0.0091363871845665, -0.008970632254700215, 0.01422836451120851, -0.008141860399336523, 0.0015614072390755828, -0.006974948598804315, -0.023987988108656766, 0.00870542511197222, 0.008930851742084564, -0.013817293626244634, -0.003368131131740689, -0.003232212517658721, 0.004899702520693243, 0.016243938423412235, -0.016601968624888573, 0.01416206272552651, -0.029650161164692993, -0.012710053525958484, 0.013452633339332352, 0.005370445105903176, 0.012729944713588888, -0.029411476226353924, -0.0038587644389197367, 0.020275088110464846, -0.02686548616604905, 0.02290063919600102, -0.020885065283797292, 0.0019989991642751603, 0.005768255819995167, 0.013671429884008752, -0.04102754982289814, -0.011151962028092805, -0.01131108594120057, 0.012716683611394426, -0.022410005423160684, -0.0032869114209971764, 0.004617919698714105, -0.011748678099230792, 0.017397590053072558, 0.006364972356794444, -0.027077652625289512, -0.012100077283948612, 0.0030299918850641093, -0.004472055956478224, -0.0017901484462446069, -0.018113650456025237, 0.008141860399336523, 0.03391999765272983, -0.008572821540608224, -0.038746766905321264, -0.007021359662517199, -0.007445691184014247, -0.006040093513820393, -0.0022791242320646687, 0.030260138338025443, 0.01244484638323049, -0.006149491320497304, -0.008897700383582275, 0.01452009292700285, -0.010966316841918693, -0.025048816679568743, -0.008652384428484684, -0.016601968624888573, 0.020023141138608733, 0.010038091842370714, 0.011993994054328383, 0.0019741358782290885, 0.014467051312192735, 0.012292352555558666, -0.0018349021050138269, -0.0228343383416416, 0.019718153483265086, -0.003944956713740206, -0.006895386642250432, 0.0011122125479477844, 0.006185957256056274, 0.005844503199492368, 0.01829929471087677, -0.030047971878784985, -0.012809506670142771, 0.03317741690803338, 0.0032554180495151627, -0.005605816398508142, -0.007074401277327313, 0.02882801939476524, 0.007180484041286253, 0.009328662456176555, 0.0065439869918713246, 0.012106707369384554, 0.02376256334118958, 0.010992837183662462, 0.006192587341492216, 0.03983411581797701, -0.006122970513092247, 0.04121319594039483, -0.010303298985098708, -0.0279528350787048, -0.005738419969872139, -0.005910804985174367, -0.00892422165664862, 0.0002243901262901954, -0.04741904159011377, -0.027024610079156818, 0.01726498648170856, 0.005128443727862268, 0.012086817113076728, -0.008937481827520506, -0.011072399140216344, 0.011821609970348734, 0.005811352306651369, -0.050018072333906184, 0.016628488966632344, 0.025154899909188972, -0.007691008070434416, -0.001571352483644818, -0.013870335241054748, -0.01352556614177287, 0.028271084767565485, 0.01654892794140104, -0.0023056448066390814, 0.0022907268815775673, 0.029650161164692993, 0.003895230374478707, -0.014864862026284727, -0.027555024364612806, 0.006709741456076321, -0.002967005142100082, 0.021495040594484587, 0.011947583456276788, 0.020314868623080497, 0.011012727439970288, -0.009540827984094434, 0.023948207596041115, -0.006494260419779181, 0.013028302283496593, -0.048135101993066455, -0.021388959227509514, 0.012650381825712428, 0.02646767545195706, 0.0020304923029265294, -0.009129757099130558, -0.009580609428032665, 0.006156121405933246, -0.013910115753670401, 0.019002093080312407, -0.0010740890910298285, -0.027316339426273737, -0.002182986596259642, -0.010283407797468303, 0.016562188112272922, -0.006298670105451156, 0.017185425456477256, 0.035192992682882264, 0.0018912586461265902, 0.0004417356994932107, -0.0027879905070232014, -0.002312275124905668, 0.004326192214242342, -0.004730633013770276, -0.01908165596818887, -0.006401438292353415, 0.018100390285153353, 0.023736041136800657, 0.01138401781231851, -0.00881150834159245, 0.010164065328298768, -0.013896855582798516, 0.003712900463853211, 0.03495430588189804, -0.020911585625541063, 0.014758778796664498, -0.00460134448512425, -0.01648262522439646, 0.01608481451030447, -0.01241832604148672, -0.009103235826064213, -0.014785300069730844, -0.022370224910545033, 0.014811820411474613, 0.0092026889702485, 0.013147645683988705, -0.021229833451756594, 0.004021203627576118, 0.01176856835553862, -0.03909153879857088, -0.002897388313700112, -0.026056604566993186, 0.015010725768520609, 0.030976196878332966, 0.010190585670042537, 0.02661353919419294, -0.6874169735556065, -0.008433587883808285, 0.0024150428461466368, -0.0201822650517165, 0.01170226656985662, 0.033973038336217364, 0.01244484638323049, 0.00290733367468467, -0.0026156057245516184, 0.00873857647047451, -0.0010235338746735145, -0.003828928588796708, -0.013247097896850414, -0.022754775453765138, 0.0069882087696762, -0.02693178888305363, -0.013459264356090872, -0.013578606825260407, 0.013154275769424647, 0.0018349021050138269, 0.0033051443887766613, 0.0077838306635214715, -0.01912143648080452, 0.012146488813322785, 0.0028012506778950855, 0.010992837183662462, 1.9864639479950606e-05, -0.004604659527842221, 0.03134748725068119, 0.01116522219896469, -0.00908997565519233, -0.0016045033764858173, -0.007465581905983363, 0.012531038425220313, 0.03633338227902554, -0.010800561912052408, -0.008254572783070116, -0.009501046540156204, 0.012212790599004783, 0.03100271908272189, -0.020924845796412947, 0.01220616051356884, 0.01612459688556528, -0.00870542511197222, -0.029305392996733695, -9.05951823455968e-05, 0.03458301364690466, -0.016933478484621147, 0.0022426580636750537, 0.0010807191764657705, -0.0077506797706804725, -0.000866067191886429, 0.009441375771232725, 0.005254417213790323, 0.018789928483717105, -0.005804721755554138, 0.03028665867976921, -0.007140703063009312, 0.01962533042451674, 0.020858544942053525, -0.012544299527414777, 0.011868020568400328, -0.021137012255653405, -0.008002626742536583, -0.015952210938940472, 0.0008097106507736657, -0.028536291910293478, 0.016641749137504228, 0.01844515845311265, -0.018259514198261117, 0.0032835963782792054, 0.018339075223492422, -0.010210475926350363, -0.0034543234065611585, 0.01770257957106136, 0.024637745794604867, 0.0018249568604445916, -0.01886948950894841, -0.010004940483868425, 0.006142861235061362, -0.0032653634104997204, 0.008519780857120688, -0.02104418919690506, -0.01138401781231851, 0.0268257056534334, -0.010422641454268243, -0.01872362576671253, 0.002589084917146561, -0.00015612000489057096, 0.012902328797568537, 0.024306237797517453, 0.005645597842446373, -0.002284096796141625, -0.004409069213514196, 0.011191742540708458, 0.023709520795056886, 0.0023454260177466673, 0.006481000248907297, 0.024266455422256646, -0.005486473463677318, -0.023484094164944545, 0.0016567159977857945, 0.023974727937784882, 0.009779514785078661, 0.01865732491235311, 0.007041250384486314, -0.0223967452522888, 0.0161908977399247, 0.02644115511021329, -0.03259396193908986, -0.00781698155636247, -0.015382016140868832, -0.005625707120477257, 0.004700797163647248, 0.000185541431018107, -0.03917109982380218, -0.0005594213748995243, 0.00531740395675435, 0.018763408141973338, -0.031877901536137176, 0.03285916908181785, -0.0017686003193318283, 0.029146269083625928, 0.007591555391911418, -0.011901171926902616, 0.010913275227108579, -0.012935480156070826, -0.011967473712584616, -0.010435902556462704, 0.008221422355890405, -0.0040709301996682615, -6.428165969786208e-05, 0.006915276898558259, -0.0026603594997361606, 0.019704893312393203, -0.004594714399688308, 0.005735104927154168, 0.003712900463853211, 0.012497887998040604, 0.0030299918850641093, 0.004753838778457363, -0.0004042337548772133, -0.016217418081668468, -0.015023985939392493, -0.014639436327494964, 0.0013152618248065662, -0.03071098973560497, 0.004594714399688308, -0.003165910499146078, 0.007558404499070419, -0.0025691944280080902, -5.557954887190824e-05, 0.011470209854308336, 0.009540827984094434, -0.006242313913584359, 0.0021531507461366134, -0.006590398055584208, -0.024770349365968863, -0.02108396970952071, -0.009766253682884198, 0.006345081634825328, 0.0355908015343291, -0.013406222741280758, 0.00816838074108029, -0.016098074681176355, 0.029835807282189684, 0.010356339668586245, 0.031029239424465657, -0.024770349365968863, -0.02789979439521726, -0.016429584540908926, 0.011244784155518573, -0.0007119154936096533, 0.014069240598100744, -0.005211320727134121, 0.004402439128078254, -0.01733128919871314, -0.011052508883908518, 0.002186301638977613, -0.015382016140868832, 0.0030830332670435793, 0.004150492156222143, -0.020858544942053525, -0.005270992427380178, 0.004017888584858146, 0.008015886913408467, -0.008228052441326347, 0.014679216840110615, -0.020818762566792718, 0.016893696109360336, 0.0021962469999621706, 0.03254092125560232, -0.006520781227184238, 0.003421172513720159, -0.0018232993390856062, -0.010422641454268243, -0.0038620794816377076, -0.003988052734735118, 0.016323501311288697, 0.017225205969092907, 0.0495672190736815, 0.0072998274417783665, -0.0018663954764958407, -0.02596378150824484, 0.009912118356442658, -0.010992837183662462, -0.01145031959800051, -0.0029968409922231103, 0.045721717366770734, 0.012776355311640482, 0.0025807973103516334, -0.0071605937849784276, -0.000942314222137663, 0.004820140564139361, 0.0036333382744686837, 0.006507521056312355, -0.006795933963727435, 0.012763095140768599, -0.006179327170620332, -0.007359499142024423, 0.004833400735011245, 0.005019045921185357, 0.024385798822748758, -0.007193744677819427, -0.018458418623984535, -0.008267833885264577, 0.003696325017432711, 0.02718373585490974, 0.010747520297242293, -0.03177182016916211, -0.03307133554105831, 0.003207349231612649, 0.002942142088884655, 0.018630804570609342, 0.0008001797865441768, -0.0007160593552147783, 0.010104393628052712, 0.002913963760120612, 0.028191521879689024, -0.006726316669666176, 0.0037825172922531804, 0.020248567768721075, 0.03850808010433704, -0.010303298985098708, 0.03662510976349731, 0.024372538651876875, 0.0003176270415093365, 0.008082188699090465, -0.01714564308121645, 0.0495672190736815, -0.01437422825344439, 0.006013572706415336, -0.0092026889702485, 0.010150804226104307, 0.005973791728138394, -0.023709520795056886, -0.0032090067529716346, -0.02821804222143279, 0.03354870541773645, 0.020593337799325533, -0.006560562205461179, 0.010097762611294192, 0.006272149763707388, -0.006504206013594383, 0.00042246672265669846, -0.0208320227376646, -0.0017022985336498297, 0.006620233905707236, -0.011708896655292563, -0.015421796653484483, -0.027846753711729726, -0.023311710080964897, 0.0031874587424741787, -0.0004220523423169521, 0.024770349365968863, 0.006335136506671416, 0.01893579222595299, 0.002832744049377099, 0.03028665867976921, 0.010429272471026763, -0.013048192539804418, -0.03317741690803338, 0.0025526189815875907, -0.0022774664778750387, 0.013790773284500865, -0.013724471498818867, -0.02718373585490974, -0.015753306513217054, -0.00592075011332828, 0.018736885937584415, 0.012119967540256437, 0.012411695956050779, 0.01611133485204824, -0.004276465642150199, 0.0010740890910298285, -0.002357028667259566, 0.005383705742436349, 0.0035869269779251556, -0.016986519168108682, -0.023126065826113363, -0.0014992492567910479, -0.005827927520241224, 0.01941316582792144, 0.00513507381329821, 0.01131108594120057, 0.014294666296890508, -0.009010413698638446, -0.01986401722550097, -0.012809506670142771, -0.007565034584506361, 0.017649537024928667, -0.003603502424345655, -0.018644064741481226, -0.011755308184666736, 0.006016887749133307, -0.007412540291173248, -0.02404103065478946, -0.0023404532208390664, 0.019718153483265086, 0.01323383772597853, -0.03230223445461809, 0.015063767383330724, -0.004289725813022083, 0.0034510083638431875, 0.07160593598713912, 0.0056157619923233445, 0.021017668855161292, 0.01005798209867854, -0.024200154567897224, -0.017357809540456907, -0.020301608452208613, -0.004773729034765188, -0.0017868332871113135, 0.011045878798472577, -0.018272774369133, -0.002821141399864201, 0.012100077283948612, -0.012862548284952886, 0.008314244483316172, 0.013247097896850414, 0.002536043535167091, -0.0018597652746445764, 0.02549966993979343, -0.017954524680272314, -0.012464736639538315, -0.002635496213690089, 0.006467740078035413, -0.02043421202357261, -0.012809506670142771, 0.00262223580998756, 0.016469365053524577, -0.012524408339784372, 0.011669115211354332, -0.026547238339833523, -0.01094642565428829, -0.0029852383427102116, 0.00966680147002249, 0.016747832367124457, -0.006766098113604406, 0.012537669441978833, -0.016999779338980565, 0.009932008612750485, 0.006378232527666328, 0.003610132742612242, -0.010747520297242293, 0.005290883149349293, 0.003096293670746108, 0.008506519754926225, 0.017397590053072558, -0.015461578097422714, -0.008400437456628574, 0.01563396311272494, -0.015753306513217054, -0.01027014762659642, 0.024664266136348634, -0.010628177828072759, -0.001583784126667854, 0.0036863796564481537, 0.010648068084380584, 0.00895074199839239, -0.010150804226104307, -0.015700263967084363, 0.0037626268031147095, -0.022410005423160684, -0.016959998826364914, -0.005360499977749263, 0.0030482248528435948, 0.013936637026736746, -0.012584080040030428, -0.01912143648080452, -0.008234682526762288, -0.007618076199316475, -0.013684690054880636, 0.00973973334114043, 0.01817995131038466, -0.013048192539804418, -0.021229833451756594, -0.023059763109108785, 0.01823299385651735, 0.012066925925446323, 0.001380734849809072, -0.0031228144781511656, -0.01019721575547848, 0.016840655425872802, 0.017729099912805128, -0.04195577295980096, -0.014665956669238731, -0.018392117769625117, -0.010362970685344764, 0.01847167879485642, 0.006176012127902361, -0.0023785769105876668, -0.0028344015707360845, 0.009971790056688716, 0.016151117227309046, -0.006759467562507175, 0.024478621881497103, -0.011105550498718633, -0.02215805845130457, 0.012226050769876666, 0.0064776852061893255, 0.009912118356442658, 0.01768931753754432, 0.005164909663421238, 0.00885128978553068, -0.029703203710825687, -0.02475708919509698, -0.010787301741180524, 0.0009870679391145443, -0.015567661327042943, 0.004475370999196195, 0.01244484638323049, -0.018524721340989113, -0.006374917484948357, 0.0016592023962395952, -0.019678372970649435, -0.0044853161273501075, -0.00453172765672428, 0.03399955867796113, 0.01312775542768088, -0.001227411912211789, 0.01337970146821441, 0.00973973334114043, -0.00899052344233062, 0.014122282212910859, -0.017609756512313016, 0.03720856473244084, 0.008771726897654219, 0.004773729034765188, 0.003848819077935179, 0.00552956948467223, -0.03482170044788888, -0.020076183684741428, 0.015328974526058718, -0.00338802162087916, 0.004594714399688308, -0.017105862568600794, -0.03285916908181785, -0.021786769941601506, -0.01936012328178875, -0.0042068488137502295, 0.0026056603635670607, -0.013711210396624405, -0.021402219398381397, -0.004167067835473288, 0.01574004634234517, 0.022807816137252676, -0.019784454337624508, -0.03933022187426479, -0.021932633683837386, -0.00824131261219823, -0.0028227989212231863, -0.016217418081668468, -0.017967786713789357, 0.00749210271338842, 0.01416206272552651, -0.018962312567696756, -0.03007449408317391, 8.816066874575628e-05, -0.03413216411197029, -0.01244484638323049, -0.00945463594210461, 0.03028665867976921, 0.03532559439160111, 0.045774758050258275, -0.01611133485204824, 0.013512305039578409, 0.00513507381329821, -0.014652696498366848, -0.0012100077051117968, 0.004946113584406127, -0.006149491320497304, -0.017636276854056783, 0.00595721604888725, 0.017344549369585023, 0.0016666613587703522, -0.004482001084632137, 0.009786144870514603, 0.009421484583602322, 0.0216143839949767, -0.0010807191764657705, -0.0039648474357093216, -0.013247097896850414, -0.01562070201053048, -0.012100077283948612, -0.009633650111520202, -0.0015895854514243032, 0.0024001249210851227, -0.0070279902136144295, 0.0008992180847274283, 0.023523876540205355, 0.015169850612950952, 0.011132070840462402, 0.0024697417494850926, 0.01768931753754432, -0.01901535511382945, 0.005174854791575151, 0.01152325146911845, 0.0020603281530495576, -0.025154899909188972, -0.007498732798824362, -0.012033775498266614, 0.005062141942180269, 0.011330976197508396, 0.0016260515033985957, 0.0059936819844462206, 0.005678748735287372, -0.0038090380996582377, -0.014241624682080394, 0.005506363719985144, -0.017211945798221023, -0.014573134541812964, 0.008612602984546453, 0.0006456137079276547, -0.019850757054629086, -0.05633000307589051, -0.017861703484169128, -0.01804734773902066, 0.019983360625993082, 0.020023141138608733, -0.007923063854660121, -0.002391837081459551, -0.0044156992989501384, -0.010011570569304367, 0.00870542511197222, 0.00326370565631009, 0.04338789376570632, 0.015461578097422714, 0.019559029570157323, 0.029411476226353924, -0.030525345480753436, -0.022913899366872905, 0.004133916942632289, -0.012955370412378651, -0.0027664422636951005, 0.01686717576761657, 0.02272825511202137, -0.023789083682933348, -0.021906111479448463, 0.013618388269198638, 0.016708051854508806, -0.007293197356342425, -0.022410005423160684, -0.0026885375956695588, 0.008300984312444287, 0.007167223870414369, -0.004442220106355196, -0.003855449163371121, -0.025207942455321666, 0.028589332593781016, -0.018988832909440524, -0.0011345894355400555, -0.007034620299050372, -0.004409069213514196, -0.03909153879857088, -0.003136074881853694, -0.03909153879857088, 0.02705113228354574, 0.011602813425672332, -0.022476308140165262, -0.005861078413082223, -0.00805566742602412, -0.028668895481657478, 0.005967161177041163, 0.011324346112072455, -0.0017719153620497994, 0.016363281823904348, -0.015580921497914828, 0.02169394688285316, 0.015209631125566603, -0.007942955042290527, -0.0023984673997261372, -0.005589241184918286, 0.0252609831388092, 0.017715839741933245, -0.007604815562783302, 0.014639436327494964, 0.003706270145586624, 0.025619013340285542, -0.013021672198060651, -0.0018498200300753412, -0.02230392405618561, -0.01916121885606533, 0.010256887455724535, 0.017172165285605372, -0.010077872354986365, 0.018153430968640888, -0.012133227711128323, -0.004634495377965249, 0.007618076199316475, -0.0324613565050807, -0.00710092208473237, 0.0053770751913391176, -0.020593337799325533, -0.0014578106407397988, 0.004680906441678133, -0.009507677556914725, 0.021349176852248707, 0.0026189207672695893, -0.0017702578406908137, 0.02307302327998067, 0.028058918308325027, -0.03964847342577063, -0.008997153527766562, 0.008513149840362166, 0.019559029570157323, 0.009766253682884198, 0.01422836451120851, -0.0049925251137803, -0.03506038724887311, 0.011138700925898344, -0.01320068729879882, -0.024120591680020762, -0.04049713553744215, 0.012259201197056377, 0.005751680606405313, -0.0001189288382534257, -0.019147958685193447, 0.0024150428461466368, 0.007014729577081257, 0.020924845796412947, 0.0013169193461655517, 0.008765096812218277, 0.012935480156070826, 0.001079061655106785, -0.015819607367576476, 0.018803188654588993, -0.020964626309028598, 0.0038355586742326504, 0.023974727937784882, 0.0005262704820585251, -0.0017221890227883004, -0.017649537024928667, -0.007041250384486314, -0.008247942697634172, 0.02835064579279679, -0.012186269325938437, -0.030737511939993897, -0.03150661302643411, 0.0005888427864751451, -0.012312242811866492, 0.0062389988708663885, -0.0008793275373812965, 0.0032388426030946628, 0.004661016185370306, 0.016495885395268344, -0.006434589185194414, 0.009156277440874327, -0.0007102579722506678, -0.0031974038706280915, 0.00036072317891957113, -0.022595651540657374, -0.03506038724887311, -0.03039274190938944, -0.02572509656990577, -0.010681218511560295, -0.0012033775032605325, -0.015342234696930602, -0.008784987999848682, -3.2684711320805806e-05, -0.03506038724887311, -0.003207349231612649, -0.014878122197156611, -0.0052776225128161195, -0.006345081634825328, -0.0035604061705200984, -0.004256574920181083, 0.02792631473696103, 0.031612694393409184, 0.021853070795960928, -0.0276080669107455, -0.0023288505713261677, 0.009129757099130558, -0.02528750348055297, -0.02015574470997273, 0.012199529496810321, -0.011689006398984736, -0.020739201541561413, 0.017914744167656663, 0.0006725488374647973, 0.008300984312444287, 0.01950598702402463, 0.011695636484420678, -0.02800587762483749, -0.0016401405513652948, 0.004607974570560192, 0.006374917484948357, 0.0038687095670736494, 0.0029454571316026258, -0.029994931195297447, -0.005947270920733337, -0.010011570569304367, 0.004515151977473136, 0.00033586000928882166, 0.002433275813926122, 0.004883126841442099, -0.0126304915694046, -0.00026313524102926253, -0.02298020208387748, -0.0023802344319466522, -0.013936637026736746, -0.02649419579370083, -0.004236684663873258, -0.011079029225652286, -0.011788458611846445, 0.0268257056534334, 0.03129444656719365, -0.005834557605677166, -0.0006306957828661406, 0.016880435938488453, -0.016999779338980565, 0.002938827046166684, -0.004730633013770276, -0.02215805845130457, -0.016601968624888573, -0.015143329339884605, 0.02229066202266857, -0.022489568311037145, 0.01280287658470683, -0.00040112584412145433, -0.007260046463501425, -0.017636276854056783, 0.011377387726882569, -0.0010061296675735222, -0.015355494867802485, 0.00585113328492831, -0.011218263813774804, -0.013989678641546861, -0.010303298985098708, -0.00781698155636247, 0.00242664572849018, -0.004730633013770276, 0.008910960554454159, 0.0033482406426022186, 0.002476372067751679, -0.022807816137252676, 0.0099850502275606, 0.010827083185118755, -0.0011221577925170196, 0.0230465029382369, 0.21768204957322806, -0.01719868562734914, 0.00478035912020113, 0.048055540967835146, 0.007286567270906482, 0.04818814267655399, -0.004286410770304112, -0.008440217969244226, -0.00017518176245337943, 0.01498420542677684, 0.0021166848105776434, 0.012829396926450597, -0.02718373585490974, -0.0012381860338758395, -0.010906645141672637, -0.00930214118311021, -0.012398434853856317, -0.028483249364160787, -0.010860233612298464, 9.877931047091003e-05, 0.02368300045331312, -0.022913899366872905, 0.019320342769173094, -0.007074401277327313, 0.006974948598804315, -0.014321187569956855, -0.02874845650688878, 0.009613759855212376, 0.015355494867802485, 0.027130693308777046, -0.011138700925898344, -0.012935480156070826, 0.03240831582159317, -0.004876496756006157, -0.011224893899210745, -0.012385174682984432, 0.009786144870514603, -0.013266989084480818, 0.047578167365866696, 0.030313179021512978, 0.01869710542496876, -0.009859076741632543, -0.015713524137956247, -0.008088818784526407, -0.006762783070886435, 0.004979264477247126, -0.023669740282441235, -0.024770349365968863, 0.011463579768872394, -0.006961688427932431, -0.015594181668786712, -0.01608481451030447, 0.010097762611294192, 0.007896543512916354, 0.008625863155418339, -0.007412540291173248, 0.018405377940497, -0.0028344015707360845, 0.025857700141269768, 0.021601123824104815, -0.004876496756006157, 0.027210256196653508, -0.020487254569705304, 0.017119122739472678, -0.015116808998140838, 0.019240779881296636, -0.006524096269902209, 0.016363281823904348, -0.001255590240975832, 0.011244784155518573, 0.01352556614177287, -0.003765941845832681, 0.007982735554906178, 0.01563396311272494, -0.023033242767365018, -0.004714057334519132, 0.03216962902060894, 0.00970658291396072, 0.026083124908736953, 0.031798340510905874, -0.015527879883104714, -0.010720999955498526, -0.028589332593781016, -0.006772728199040349, -0.009083345569756386, -0.022714994941149487, -0.00020626073904373156, -0.012603971227660833, -0.0032869114209971764, -0.014453791141320851, -0.005602501355790171, -0.0230465029382369, -0.02503555650869686, -0.020407691681828842, 0.023961467766913, 0.03214310867886517, 0.011602813425672332, 0.007797090834393356, 0.004090820455976087, 0.001949272708598339, -0.02465100596547675, 0.027157213650520814, 0.012504518083476546, 0.005406911041462146, -0.0037526814421301523, 0.01105913896934446, 0.01352556614177287, 0.008499889669490283, 0.005552775249359316, -0.013001781941752824, -0.002343768496387682, -0.016655011171021267, 0.0022244250958955688, 0.0004042337548772133, 0.016456104882652693, 0.0033184047924791904, 0.010833713270554697, -0.01650914556614023, 0.017278246652580445, -0.0019956838887265444, -0.017782140596292666, -0.0023470835391056527, -0.001525770064196105, -0.003331665196181719, 0.00018937449281650683, -0.018392117769625117, -0.0072335256560963675, -0.006189272298774245, -0.009076715484320444, -0.030021451537041218, 0.030154055108405214, 0.01019721575547848, 0.02718373585490974, -0.01452009292700285, -0.011669115211354332, -0.01498420542677684, 0.020301608452208613, 0.0053074583629391485, -0.01568700379621248, -0.0030565126924691666, 0.030047971878784985, -0.001118013989119556, 0.0019476151872393536, -0.007120812341040197, 0.02112375208478152, 0.012988520839558362, 0.02315258616785713, -0.02368300045331312, -0.014122282212910859, -0.0012688505282630383, -0.02856281225203725, -0.004786989671298362, 0.0012298983106655897, -0.008413697627500459, 0.04259227233752234, 0.0027780451460386437, -0.010316559155970592, -0.018418638111368884, 0.0035968723389097133, -0.020778982054177064, -0.01333992095559876, -0.0032769660600126187, 0.005761625734559225, -0.0033929941849561163, -0.0016873806085883156, -0.0012000624605425613, -0.17153599928797642, 0.014878122197156611, 0.009129757099130558, -0.018564501853604764, 0.0008412040222556795, -0.022051977084329502, 0.034158684453714054, -0.005257732256508294, -0.014055980427228859, -0.0007077716320045284, 0.02492947327907663, -0.0006058326132353911, -0.020500514740577187, 0.0038852850134941494, 0.001182658253442569, -0.0017337919051318435, -0.025817917766008957, -0.012491257912604662, 0.02800587762483749, 0.004133916942632289, 0.016973258997236798, -0.00369300997471474, 0.010263517541160477, -0.011622704613302738, 0.005731789884436197, -0.0009870679391145443, -0.013419482912152642, 0.035829488335313325, -0.006010257663697365, -0.02262217188240114, 0.010966316841918693, -0.007896543512916354, 0.02728981722188481, 0.026587018852449174, 0.012033775498266614, 0.013910115753670401, 0.024120591680020762, -0.0036167628280481838, -0.019519247194896512, 0.00784350189810624, 0.012531038425220313, 0.005164909663421238, -0.004899702520693243, -0.024518402394112754, 0.012782985397076424, 0.014838341684540958, 0.0212696158270174, -0.0019807659636650304, 0.022794555966380792, 0.010396121112524475, 0.023059763109108785, -0.03927718119077725, -0.01077404157030864, -0.008871180041838506, 0.014851601855412844, 0.015130069169012722, -0.005479843378241376, 0.012723313696830368, -0.010813822082924291, -0.00863249324085428, -0.004631180335247278, -0.024133851850892646, -0.003981422649299176, -0.023563657052821006, -0.016257200456929275, -0.013320029767968354, -0.018922532055081105, 0.029756244394313222, 0.0008333306793851761, 0.004607974570560192, -0.004163752792755317, -0.0031327596063050783, -0.0036731192527456246, 0.005953901006169279, 0.011635964784174621, -0.018896011713337334, -0.011151962028092805, 0.0333365426837863, 0.0023139326462646537, -0.008572821540608224, 0.02039443151095696, 0.04540346954055521, 0.006404753335071386, 0.007995996657100641, 0.0043460824705501685, 0.013061453641998882, -0.0070942919992964286, 0.009892227168812254, -0.009189428799376616, 0.0011478498392425841, 0.013074713812870765, -0.033283498275008455, -0.03163921473515295, -0.022237621339181033, 0.004399124085360283, 0.028774978711277707, 0.0161908977399247, -0.02034139082746942, -0.0010707739318965353, -0.023629959769825584, -0.00873857647047451, 0.014533353097874735, -0.004581453763155135, 0.03720856473244084, 0.02779371116559703, -0.0014544955980218277, -0.0047604688638933045, 0.01152325146911845, 0.033310022342042535, 0.013293509426224587, -0.034450411938185814, 0.012550929612850719, 0.0066500697558302645, 0.03999324159372993, 0.02015574470997273, 0.020606597970197416, 0.014851601855412844, -0.00463781042068322, -0.005486473463677318, 0.014639436327494964, 0.04529738444828982, 0.001723846660562608, -0.02465100596547675, 0.016575448283144806, 0.0012473025177655822, -0.023842124366420886, -0.10465075118645366, -0.04786989485033846, 0.031108800449696963, 0.041186675598651065, -0.001269679288942531, 0.03442389159644205, -0.0005154964186021358, 0.01009113252585825, -0.027395900451505042, 0.008208162185018521, -0.018710365595840647, -0.017185425456477256, -0.018962312567696756, -0.021627644165848583, 0.002643784053315661, 0.009580609428032665, 0.012484627827168719, 0.005934010284200164, -0.025393586710173197, 0.025446627393660735, -0.018418638111368884, 0.001250617560483553, -0.007511992969696246, -0.007836871812670298, -0.001048397044304264, -0.01101935845672881, -0.01981097654201343, 0.00638486261310227, 0.006268834720989417, 0.006182642213338303, 0.0006957544275289001, -0.005612446949605373, -0.002579139788992648, -0.011894541841466674, -0.01280287658470683, -0.007896543512916354, -0.00895074199839239, -0.01729150682345233, 0.0013102891443142874, -0.0126304915694046, 0.00845347814011611, 0.004203533771032259, -0.0068224543054712025, -0.021070709538648827, 0.006484315291625268, -0.012670273013342831, 0.015647223283596825, 0.022370224910545033, -0.021349176852248707, -0.018856229338076527, -0.031877901536137176, 0.006842345027440318, -0.04134579764911367, 0.008983893356894678, 0.023815604024677115, 0.02119005293914094, 0.014427269868254504, 0.0037825172922531804, -0.02465100596547675, -0.023165846338729014, -0.026388114426725756, 0.016495885395268344, -0.018259514198261117, 0.0005196402802072607, -0.00599036694172825, 0.0010243627517683297, -0.01920099936868098, 0.006139546192343391, -0.0036267081890327415, -0.0032802811027305896, -0.005284253063913351, 0.025486409768921543, -0.0119807338834565, 0.020778982054177064, -0.03155965370992165, 0.005333979170344206, -0.009620389940648318, -0.03270004330606493, 0.015501359541360945, -0.0019824237178546608, -0.02610964525048072, -0.027740670482109497, -0.010681218511560295, -0.0228343383416416, 0.013273619169916762, 0.007220265485224484, 0.021985674367324924, -0.0002836473588850139, 0.017729099912805128, -0.03906501473153679, -0.009607129769776433, 0.015368755969996949, 0.016800874913257147, -0.03121488367931719, -0.014652696498366848, 0.0034543234065611585, 0.0012671930069040529, 0.010535354769324413, 0.0003497419543971393, 0.007909803683788238, -0.02671962242381317, -0.013857075070182865, -0.05617087730013759, 0.009076715484320444, 0.017278246652580445, -0.024213414738769107, -0.011496731127374683, 0.0002695582236068231, 0.004581453763155135, -0.02543336722278885, 0.020447472194444493, -0.019718153483265086, -0.010621546811314239, 0.007180484041286253, -0.014718998284048846, 0.007538513777101304, -0.014480311483064619, -0.02390842708342546, 0.038746766905321264, -3.81494284487664e-05, 0.03362827016825807, 0.0075451438625372454, 0.009587239513468607, -0.02207849742607327, 0.022277401851796687, 0.01729150682345233, -0.00524447161997512, 0.00016326816761460297, -0.0323817954798494, 0.0010550272461555283, -0.008891070298146333, -0.0021448629065110416, 0.010508834427580646, -0.02368300045331312, -0.00344106300285863, 0.014997465597648724, 0.00610308025678442, -0.013605128098326754, 0.005645597842446373, 0.0014453791141320852, 0.02400124827952865, -0.018100390285153353, 0.0009729788329401839, -0.06916602729380932, 0.004445535149073167, -0.025778137253393306, -0.04219445976078519, 0.01719868562734914, -0.008765096812218277, 0.00863249324085428, 0.018259514198261117, 0.01048894323995024, 0.015580921497914828, 0.0069948393207734305, -0.011695636484420678, -0.0018216418177266205, -0.0071605937849784276, 0.007571664669942303, -0.009779514785078661, 0.00027639558652413, 0.0049925251137803, -0.017384329882200674, 0.03325697793326469, 0.0033084594314946327, 0.0279528350787048, 0.009282250926802382, 0.01002483074017625, 0.01312775542768088, -0.00305154012839221, -0.00013498630197328473, 0.03909153879857088, -0.020845282908536485, -0.011549772742184798, 0.0006742063588237828, 0.0021100544923110566, -0.015726786171473287, 0.02518142025093274, -0.003769256888550652, 0.008247942697634172, -0.00656387771384044, -0.019559029570157323, 0.04171708988410705, 0.024266455422256646, 0.015713524137956247, -0.04603996519298627, 0.012060295840010381, 0.01562070201053048, 0.0043493975132681394, -0.008659014513920626, 0.011205002711580342, -0.013034932368932535, -0.00820153209958258, -0.026626799365064825, 0.0012249256301733109, 0.004697482120929276, 0.008320874568752114, -0.010482313154514299, 1.5435885934281828e-05, 0.010157434311540248, -0.01784844331329724, 0.010727630040934468, 0.02864237513991371, 0.03768593833440929, -7.464131371067436e-05, -0.005473212827144145, -0.009401594327294496, 0.0013741046479578078, 0.014612915054428617, -1.4749559401629837e-05, -0.019174479026937214, -0.003573666574222627, 0.00513507381329821, 0.0010434244802273074, -0.011397277983190396, -0.002643784053315661, -0.007876653256608527, -0.0010301640765247788, 0.016999779338980565, -0.006573822841994353, -0.026480935622828945, -0.03100271908272189, 0.023749303170317697, -0.0005507192713495281, 0.009123127013694617, 0.02678592514081775, -0.006272149763707388, 0.008446848054680168, -0.0017536823942703142, 0.0063053006565483875, -0.008745206555910452, 0.014639436327494964, 0.012537669441978833, 0.011423799256256742, -0.0015721812443243108, -0.027767190823853264, -0.02254260899452468, -0.018246254027389233, -0.002685222552951588, -0.0075451438625372454, 0.021919373512965502, -0.018577762024476648, 0.05023023879314664, -0.0019592179531675745, -0.0031261295208691365, -0.001914464294398354, -0.007392650034865422, 0.025340546026685663, 0.014546613268746619, 0.00881150834159245, -0.015435057755678947, -0.026083124908736953, 0.03609469547804132, 0.0038123531423762086, 0.004581453763155135, -0.01817995131038466, -0.006325190912856214, 0.020036401309480617, -0.00816838074108029, 0.02465100596547675, -0.004598029442406279, 0.01344600325389641, 0.02446536171062522, 0.004836715777729216, 0.010780671655744582, -0.002753181859992572, -0.005131758770580239, -0.009003783613202504, 0.00973973334114043, 0.0021398903424340848, -0.011503361212810625, -0.011006097354534346, 0.004584768805873106, 0.010687848596996237, -0.019930318079860388, -0.02169394688285316, -0.010429272471026763, 0.01059502646957047, -0.0198374968837572, 0.005967161177041163, -0.014825080582346497, 0.005821297434805282, 0.005350554849595349, 0.043467454790937624, 0.0022376854995980974, 0.008871180041838506, 0.008751836641346393, -0.002932196727900097, -0.027740670482109497, -0.014639436327494964, -0.0161908977399247]\n","1536\n"]}],"source":["# Texting the embedding function\n","\n","input_text = \"This is for demonstration.\"\n","outcome = embedding_function.embed_query(input_text)\n","print(outcome)\n","print(len(outcome))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"2aBhDj2MuC8Q"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\jmgarzonv\\Desktop\\EAFIT\\Experiencias - RAG\\Building AI APP\\.venv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n","  warnings.warn(\n"]}],"source":["# Create a database from the documents and embedding function\n","db = Chroma.from_documents(documents=documents[:10], embedding=embedding_function, persist_directory=\"my-embeddings\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LmBkTf4WuC8Q"},"outputs":[],"source":["# Persist the data to disk\n","db.persist()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"9ZWmKeTruC8Q"},"outputs":[{"data":{"text/plain":["dict_keys(['ids', 'embeddings', 'documents', 'metadatas'])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["db.get().keys()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"AdlEoQs9uC8Q"},"outputs":[{"data":{"text/plain":["'gpu=\"A10G\",\\n           python_version=\"python3.8\",\\n           python_packages=[\\n               \"diffusers[torch]>=0.10\",\\n               \"transformers\",\\n               \"torch\",\\n               \"pillow\",\\n               \"accelerate\",\\n               \"safetensors\",\\n               \"xformers\",],\\n           max_length=\"50\",\\n           verbose=False)\\nllm._deploy()\\nresponse = llm._call(\"Running machine learning on a remote GPU\")\\nprint(response)\\nprevious\\nBanana\\nnext\\nBedrock\\nBy Harrison Chase\\n    \\n      Â© Copyright 2023, Harrison Chase.\\n      \\n  Last updated on Jun 06, 2023.'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["db.get()['documents'][0]"]},{"cell_type":"markdown","metadata":{"id":"j78hT1DjuC8Q"},"source":["## Alternative: use the provided embeddings\n","\n","We have already executed the step above to embed all documents and stored the result in the `chroma-data-langchain-docs` folder. Instead of embedding all the documents yourself, you can use these embeddings at no cost.\n","\n","The result of this step is the same as the step above, but will not call the OpenAI API and cost nothing."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"3K4FUGKVuC8R"},"outputs":[],"source":["# Import chroma\n","from langchain.vectorstores import Chroma\n","\n","# Import OpenAIEmbeddings\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Create the embedding function\n","embedding = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\",chunk_size = 1)\n","\n","# Load the database from existing embeddings\n","db = Chroma(persist_directory=\"chroma-data-langchain-docs\", embedding_function=embedding)"]},{"cell_type":"markdown","metadata":{"id":"VOC117g0uC8R"},"source":["# Step 5: query the vector database\n","\n","Now that we have a vector database, we can query it. A vector database stores embeddings (vectors) and allow to search through them using K-Nearest Neighbors algorithm (or a variation of it). When we query it the following will happen:\n","1. Embed the text query to obtain a vector. It is crucial that this embedding is made using the same embedding technique that was used to embed the documents;\n","2. Calculate the distance (or similarity) between the query vector and all other vectors;\n","3. Sort results by similarity;\n","4. Return the most similar documents.\n","\n","To do this with LangChain, we can use the `.similarity_search_with_score()` method of the database."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"85aPx_nWuC8R"},"outputs":[{"data":{"text/plain":["'previous\\nIntegrations\\nnext\\nAleph Alpha\\nBy Harrison Chase\\n    \\n      Â© Copyright 2023, Harrison Chase.\\n      \\n  Last updated on Jun 06, 2023.'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["db.get()['documents'][0]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"uHm75ZzxuC8R"},"outputs":[],"source":["# Call the `similarity_search_with_score` method on `db`\n","results = db.similarity_search_with_score(\"how do i load data from wikipedia?\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fu6JaNfFuC8R"},"outputs":[{"name":"stdout","output_type":"stream","text":["score 0.2894218862056732\n",".ipynb\n",".pdf\n","Wikipedia\n"," Contents \n","Installation\n","Examples\n","Wikipedia#\n","Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n","This notebook shows how to load wiki pages from wikipedia.org into the Document format that we use downstream.\n","Installation#\n","First, you need to install wikipedia python package.\n","#!pip install wikipedia\n","Examples#\n","WikipediaLoader has these arguments:\n","query: free text which used to find documents in Wikipedia\n","optional lang: default=â€enâ€. Use it to search in a specific language part of Wikipedia\n","optional load_max_docs: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments. There is a hard limit of 300 for now.\n","-----------------\n"]}],"source":["for (doc, score) in results:\n","    print('score', score)\n","    print(doc.page_content)\n","    print('-----------------')\n","    break"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"wXD_YchguC8S"},"outputs":[{"name":"stdout","output_type":"stream","text":["score 0.2894218862056732\n",".ipynb\n",".pdf\n","Wikipedia\n"," Contents \n","Installation\n","Examples\n","Wikipedia#\n","Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n","This notebook shows how to load wiki pages from wikipedia.org into the Document format that we use downstream.\n","Installation#\n","First, you need to install wikipedia python package.\n","#!pip install wikipedia\n","Examples#\n","WikipediaLoader has these arguments:\n","query: free text which used to find documents in Wikipedia\n","optional lang: default=â€enâ€. Use it to search in a specific language part of Wikipedia\n","optional load_max_docs: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments. There is a hard limit of 300 for now.\n","-----------------\n","score 0.32451340556144714\n",".ipynb\n",".pdf\n","Wikipedia\n"," Contents \n","Installation\n","Examples\n","Running retriever\n","Question Answering on facts\n","Wikipedia#\n","Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n","This notebook shows how to retrieve wiki pages from wikipedia.org into the Document format that is used downstream.\n","Installation#\n","First, you need to install wikipedia python package.\n","#!pip install wikipedia\n","WikipediaRetriever has these arguments:\n","optional lang: default=â€enâ€. Use it to search in a specific language part of Wikipedia\n","optional load_max_docs: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments. There is a hard limit of 300 for now.\n","-----------------\n","score 0.34097224473953247\n",".md\n",".pdf\n","Wikipedia\n"," Contents \n","Installation and Setup\n","Document Loader\n","Retriever\n","Wikipedia#\n","Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n","Installation and Setup#\n","pip install wikipedia\n","Document Loader#\n","See a usage example.\n","from langchain.document_loaders import WikipediaLoader\n","Retriever#\n","See a usage example.\n","from langchain.retrievers import WikipediaRetriever\n","previous\n","WhyLabs\n","next\n","Wolfram Alpha\n"," Contents\n","  \n","Installation and Setup\n","Document Loader\n","Retriever\n","By Harrison Chase\n","    \n","      Â© Copyright 2023, Harrison Chase.\n","      \n","  Last updated on Jun 06, 2023.\n","-----------------\n","score 0.35549405217170715\n",".ipynb\n",".pdf\n","Wikipedia\n","Wikipedia#\n","Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n","First, you need to install wikipedia python package.\n","!pip install wikipedia\n","from langchain.utilities import WikipediaAPIWrapper\n","wikipedia = WikipediaAPIWrapper()\n","wikipedia.run('HUNTER X HUNTER')\n","-----------------\n"]}],"source":["# Print the results\n","for (doc, score) in results:\n","    print('score', score)\n","    print(doc.page_content)\n","    print('-----------------')"]},{"cell_type":"markdown","metadata":{"id":"FWyFg7bDuC8S"},"source":["# Step 6: Create a QA chain\n","\n","Let's put it all together into a chat-like application. We want the user to ask a question, then search for relevant documents. We'll then create a prompt that includes the documents and the question so GPT can answer it (if possible).\n","\n","First, we'll query the database in a similar manner to previous step. We'll use `.similarity_search()`:\n","\n","```python\n","question = \"show an example of adding memory to a chain\"\n","context_docs = db.similarity_search(question)\n","```\n","\n","Next, we will create a prompt that contains the question and the relevant documents:\n","\n","> You can think of a PromptTemplate as an fstring in python: values in curly brances are used as placeholder and will be replaced by values we pass when running the chain.\n","\n","```python\n","prompt = PromptTemplate(\n","    template=\n","    \"\"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","        <context>\n","        {context}\n","        </context>\n","Question: {question}\n","Helpful Answer:\"\"\",\n","    input_variables=[\"context\", \"question\"]\n",")\n","```\n","\n","To call the LLM with this prompt, we need to create an `LLMChain` and pass it an LLM and the prompt:\n","\n","```python\n","llm = ChatOpenAI(temperature=0)\n","qa_chain = LLMChain(llm=llm, prompt=prompt)\n","```\n","\n","We can now call our chain like so:\n","\n","```python\n","qa_chain({\"context\": \"<the context>\", \"question\": \"<the question>\"})\n","```\n","\n","This will return a dict with a `text` key containing the LLM response."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TF9wSc5EuC8S"},"outputs":[],"source":["# Import\n","from langchain.prompts import PromptTemplate\n","from langchain.chains.llm import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.schema import HumanMessage\n","\n","# Set the question variable\n","question = \"show an example of adding memory to a chain\"\n","\n","# Query the database as store the results as `context_docs`\n","context_docs = db.similarity_search(question)\n","\n","# Create a prompt with 2 variables: `context` and `question`\n","prompt = PromptTemplate(\n","    template=\"\"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","\n","<context>\n","{context}\n","</context>\n","\n","Question: {question}\n","Helpful Answer, formatted in markdown:\"\"\",\n","    input_variables=[\"context\", \"question\"]\n",")\n","\n","# Create an LLM with ChatOpenAI\n","llm = AzureChatOpenAI(\n","    openai_api_base=OPENAI_API_BASE,\n","    openai_api_version=OPENAI_API_VERSION,\n","    deployment_name=\"gpt-35-turbo\",\n","    openai_api_key=OPENAI_API_KEY,\n","    openai_api_type=OPENAI_API_TYPE,\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"KiZzEvuKuC8S"},"outputs":[{"name":"stdout","output_type":"stream","text":["To add memory to a chain, you can use the `ConversationChain` class from the `langchain.chains` module. In the given example, the memory is added to a conversation chain using the `ConversationBufferMemory` class from the `langchain.memory` module:\n","\n","```\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory\n","\n","conversation = ConversationChain(\n","    llm=chat,\n","    memory=ConversationBufferMemory()\n",")\n","```\n","\n","This creates a `ConversationChain` object called `conversation` with the specified language model (`llm`) and memory (`memory`). The `ConversationBufferMemory` class allows the chain to persist data across multiple calls.\n","\n","You can then use the `run` method of the conversation chain to interact with it and access the memory:\n","\n","```\n","conversation.run(\"Answer briefly. What are the first 3 colors of a rainbow?\")\n","conversation.run(\"And the next 4?\")\n","```\n","\n","In the above example, the conversation chain is asked two questions. The first question is about the first three colors of a rainbow, and the second question asks for the next four colors. The answers are returned by the `run` method.\n","\n","By using the `ConversationBufferMemory` class, the conversation chain can remember previous inputs and provide context-aware responses.\n"]}],"source":["# Create the chain\n","qa_chain = LLMChain(llm=llm, prompt=prompt)\n","\n","# Call the chain\n","result = qa_chain({\n","    \"question\": question,\n","    \"context\": \"\\n\".join([doc.page_content for doc in context_docs])\n","})\n","\n","# Print the result\n","print(result[\"text\"])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"env-rag","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
